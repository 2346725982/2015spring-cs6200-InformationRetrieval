#! /usr/bin/python

import math
import time
import re
import stemming
import operator
from stemming.porter2 import stem

meaningless_word = set(["Document", "will", "or", "a", "of", "the", "on", "something", "by", "about", "with", "as", "to", "over", "either", "which", "in", "how", "and", "one", "discuss", "report", "include", "some", "an", "any", "has", "at", "must", "being", "against", "into", "its", "used", "certain", "US", "even", "other", "been", "doing", "since", "use", "both"])

def _query() : 
    query_path = "/Users/Ken/Desktop/6200/AP_DATA/query_desc.51-100.short.txt"
    result_path = "/Users/Ken/Desktop/6200/assignment_2/result/BM25.txt"
    index_path = "/Users/Ken/Desktop/6200/assignment_2/Index2/index.txt"

    source = open(query_path, 'r')
    result = open(result_path, "w")
    index = open(index_path, 'r')

    global total_docnum
    global v_size
    global avg_len

    score_dict = {} 

    offset = {}
    with open("/Users/Ken/Desktop/6200/assignment_2/Index2/offset.txt", 'r') as o :
        for l in o :
            l = l.split()
            offset[l[0]] = (int(l[1]), int(l[2])) 

    doc_len = {}
    with open("/Users/Ken/Desktop/6200/assignment_2/Index2/doc_len.txt", 'r') as d :
        for l in d :
            l = l.split()
            doc_len[l[0]] = l[1]
    
    for line in source :
        print line
        starttime = time.time()
        words = line_process(line)
        if len(words) == 0 :
            break

        score_dict.clear()

        for word in words[1:] :
            word = stem(word)

            if word not in offset :
                continue
            
            index.seek(offset[word][0])
            data = index.read(offset[word][1]-1)

            data2 = data.split(';')
            find = sorted(data2, key = lambda x: len(x.split())-1, reverse = True)
            for i in range(0, min(len(data2)-1, 1000)):
                doc = data2[i].split()[0]
                tf = len(data2[i].split()) - 1
                
                #TF-IDF
                #Qscore = (float(tf) / (tf + 0.5 + 1.5 * (float(doc_len[doc]) / 245 ))) * math.log(84678.0 / len(find))

                #BM25
                tfq = line.split().count(word)
                tmp1 = math.log((84678 + 0.5) / (len(find) + 0.5))
                tmp2 = (tf + 1.2 * tf) / (tf + 1.2 * ((1 - 0.75) + 0.75 * len(find) / 245))
                tmp3 = (tfq + 500 * tfq) / (tfq + 500)
                score = tmp1 * tmp2 * tmp3
                if doc in score_dict :
                    score_dict[doc] += score
                else :
                    score_dict[doc] = score

        write_result(result, words[0], score_dict)


    result.close()
    source.close()
    index.close()

def line_process(line) :
    line = line.replace(',', '')
    line = line.replace('.', '')

    tmp = line.split()
    words = line.split() 
    for t in tmp :
        if t in meaningless_word : 
            words.remove(t)

    return words

def write_result(target, query_num, score_dict) :
    sorted_dic = sorted(score_dict.items(), key=operator.itemgetter(1), reverse = True)
    i = 0
    for key in sorted_dic :
        i += 1
        if i > 100 :
            break
        line = str(query_num) + " Q0 " + key[0] + " " + str(i) + " " + str(key[1]) + " Exp\n"
        target.write(line)

## main function ##
if __name__ == "__main__" : 
    total_docnum = 84678
    avg_len = 426 #245 #426
    v_size = 153130
    _query()
